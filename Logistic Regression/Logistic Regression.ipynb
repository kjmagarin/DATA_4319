{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "broken-configuration",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-fighter",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "written-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, RDatasets, Plots, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-jacob",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sunset-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = dataset(\"datasets\", \"iris\");\n",
    "\n",
    "x_data = [[x[1], x[2], x[3], x[4]] for x in zip(iris.SepalLength[1:100], iris.SepalWidth[1:100], iris.PetalLength[1:100], iris.PetalWidth[1:100])]\n",
    "y_data = [iris.Species[i] == \"versicolor\" ? 1 : 0 for i = 1:100];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-swimming",
   "metadata": {},
   "source": [
    "### Training the model \n",
    "Training the model by applying Sigmoid, Cross Entropy and Cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conscious-sending",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average_cost (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σ(x) = 1/(1+exp(-x))\n",
    "\n",
    "function cross_entropy_loss(x, y, w, b)\n",
    "    return -y*log(σ(w'x + b))-(1-y)*log(1-σ(w'x+b))\n",
    "end\n",
    "\n",
    "function average_cost(features, labels, w, b)\n",
    "    N = length(features)\n",
    "    return (1/N)*sum([cross_entropy_loss(features[i], labels[i], w, b) for i = 1:N])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-warner",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "Using gradient descent to train the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "turned-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function batch_gradient_descent(features, labels, w, b, α)\n",
    "    \n",
    "    del_w = [0.0 for i = 1:length(w)]\n",
    "    del_b = 0.0\n",
    "    \n",
    "    N = length(features)\n",
    "    \n",
    "    for i = 1:N\n",
    "        del_w += (σ(w'features[i]+b) - labels[i])*features[i]\n",
    "        del_b += (σ(w'features[i]+b) - labels[i])\n",
    "    end\n",
    "    \n",
    "    w = w - α*del_w\n",
    "    b = b - α*del_b\n",
    "    \n",
    "    return w, b\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-welcome",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Checking the descent model by testing the weights and bias return value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "plain-shame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.002325, -0.001645, 0.006995, 0.0027], 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.0, 0.0, 0.0, 0.0]\n",
    "b = 0.0\n",
    "\n",
    "w, b = batch_gradient_descent(x_data, y_data, w, b, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-worker",
   "metadata": {},
   "source": [
    "### Training Batch Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tough-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_batch_gradient_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_batch_gradient_descent(features, labels, w, b, α, epochs)\n",
    "    \n",
    "    for i = 1:epochs\n",
    "        \n",
    "        w, b = batch_gradient_descent(features, labels, w, b, α)\n",
    "        \n",
    "        if i == 1\n",
    "            println(\"Epoch \", i, \" with loss: \", average_cost(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == epochs/10\n",
    "            println(\"Epoch \", i, \" with loss: \", average_cost(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == epochs/8\n",
    "            println(\"Epoch \", i, \" with loss: \", average_cost(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == epochs/4\n",
    "            println(\"Epoch \", i, \" with loss: \", average_cost(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == epochs/2\n",
    "            println(\"Epoch \", i, \" with loss: \", average_cost(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "        if i == epochs\n",
    "            println(\"Epoch \", i, \" with loss: \", average_cost(x_data, y_data, w, b))\n",
    "        end\n",
    "        \n",
    "    end\n",
    "    \n",
    "    return w, b\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "other-diesel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.6885068166534946\n",
      "Epoch 100 with loss: 0.4372119701982426\n",
      "Epoch 125 with loss: 0.4032304652270559\n",
      "Epoch 250 with loss: 0.30147523091503375\n",
      "Epoch 500 with loss: 0.22125875407731235\n",
      "Epoch 1000 with loss: 0.1670611141189582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.4091, 2.0746, -3.44367, -3.42421], 1.5163102496971033)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.0, 0.0, 0.0, 0.0]\n",
    "b = 0.0\n",
    "\n",
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.001, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-custom",
   "metadata": {},
   "source": [
    "**The goal is to get our loss under 0.5 with the data we have.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-harris",
   "metadata": {},
   "source": [
    "### Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "grand-prediction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(x, y, w, b)\n",
    "    if σ(w'x+b) >= .5\n",
    "        return 1\n",
    "    else\n",
    "        return 0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bacterial-inquiry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "\n",
    "for i = 1:length(x_data)\n",
    "    mean_error += (predict(x_data[i], y_data[i], w, b) - y_data[i])^2\n",
    "end\n",
    "\n",
    "println(mean_error/length(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-marble",
   "metadata": {},
   "source": [
    "**The average error of flowers we failed to predict is 0.03.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "derived-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[x[1], x[2], x[3], x[4]] for x in zip(iris.SepalLength[51:150], iris.SepalWidth[51:150], iris.PetalLength[51:150], iris.PetalWidth[51:150])]\n",
    "y_data = [iris.Species[i] == \"versicolor\" ? 1 : 0 for i = 51:150];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "digital-chair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 with loss: 0.6916241547799581\n",
      "Epoch 1000 with loss: 0.437548420314824\n",
      "Epoch 1250 with loss: 0.4035606937374733\n",
      "Epoch 2500 with loss: 0.30171843121989106\n",
      "Epoch 5000 with loss: 0.22138802408409863\n",
      "Epoch 10000 with loss: 0.16711664452781605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([2.40807, 2.07383, -3.44224, -3.42301], 1.5159061035780015)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = [0.0, 0.0, 0.0, 0.0]\n",
    "b = 0.0\n",
    "\n",
    "w, b = train_batch_gradient_descent(x_data, y_data, w, b, 0.0001, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "detailed-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    }
   ],
   "source": [
    "mean_error = 0.0\n",
    "\n",
    "for i = 1:length(x_data)\n",
    "    mean_error += (predict(x_data[i], y_data[i], w, b) - y_data[i])^2\n",
    "end\n",
    "\n",
    "println(mean_error/length(x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-translator",
   "metadata": {},
   "source": [
    "**After testing the remaining Iris dataset the average error reamined at 0.03.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-senegal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
